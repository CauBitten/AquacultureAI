{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51e567ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from skimage import measure                       \n",
    "from shapely.geometry import Polygon, MultiPolygon \n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from Utils.training import iou_np\n",
    "from Utils.build_dataset import paths_dataset\n",
    "from Utils.coco_dataset import get_annotations, create_sub_mask_annotation\n",
    "from torchvision import transforms\n",
    "from Utils.training import training_loop, predict, iou_np\n",
    "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253d8a92",
   "metadata": {},
   "source": [
    "## Construindo o Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95fa3abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Dataset/Fish_Dataset/Fish_Dataset/'\n",
    "df_train_pd, df_valid_pd, df_test_pd = paths_dataset(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "330f4726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "namespace(name='fish_train', thing_classes=['fish'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DatasetCatalog.register('fish_train', lambda: get_annotations(df_train_pd))\n",
    "MetadataCatalog.get('fish_train').set(thing_classes=['fish'])\n",
    "#fish_metadata = MetadataCatalog.get(\"fish_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fb9211b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "namespace(name='fish_valid', thing_classes=['fish'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DatasetCatalog.register('fish_valid', lambda: get_annotations(df_valid_pd))\n",
    "MetadataCatalog.get('fish_valid').set(thing_classes=['fish'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcc7e82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "namespace(name='fish_test', thing_classes=['fish'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DatasetCatalog.register('fish_test', lambda: get_annotations(df_test_pd))\n",
    "MetadataCatalog.get('fish_test').set(thing_classes=['fish'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e9885e",
   "metadata": {},
   "source": [
    "## Treinando o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "838d2c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"fish_train\",)\n",
    "cfg.DATASETS.TEST = (\"fish_valid\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\n",
    "cfg.SOLVER.BASE_LR = 0.0001  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 300    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512   # The \"RoIHead batch size\". 128 is faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "cfg.OUTPUT_DIR = 'output_detectron2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3dc66419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/20 08:12:24 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/20 08:13:28 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 5400 images left.\n",
      "\u001b[32m[12/20 08:13:28 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|    fish    | 5400         |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[12/20 08:13:28 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[12/20 08:13:28 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[12/20 08:13:28 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[12/20 08:13:28 d2.data.common]: \u001b[0mSerializing 5400 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/20 08:14:04 d2.data.common]: \u001b[0mSerialized dataset takes 5423.01 MiB\n",
      "\u001b[32m[12/20 08:14:04 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=2\n",
      "\u001b[32m[12/20 08:14:05 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/20 08:14:05 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[12/20 08:14:23 d2.utils.events]: \u001b[0m eta: 0:01:40  iter: 19  total_loss: 1.437  loss_cls: 0.5989  loss_box_reg: 0.1405  loss_mask: 0.6934  loss_rpn_cls: 0.000838  loss_rpn_loc: 0.005418    time: 0.3757  last_time: 0.3841  data_time: 0.4787  last_data_time: 0.0035   lr: 6.427e-06  max_mem: 2420M\n",
      "\u001b[32m[12/20 08:14:35 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 39  total_loss: 1.279  loss_cls: 0.4853  loss_box_reg: 0.126  loss_mask: 0.6686  loss_rpn_cls: 0.000726  loss_rpn_loc: 0.004942    time: 0.3520  last_time: 0.3118  data_time: 0.0035  last_data_time: 0.0036   lr: 1.3087e-05  max_mem: 2420M\n",
      "\u001b[32m[12/20 08:14:41 d2.utils.events]: \u001b[0m eta: 0:01:16  iter: 59  total_loss: 1.069  loss_cls: 0.3149  loss_box_reg: 0.1402  loss_mask: 0.6173  loss_rpn_cls: 0.000356  loss_rpn_loc: 0.005536    time: 0.3407  last_time: 0.2703  data_time: 0.0035  last_data_time: 0.0032   lr: 1.9747e-05  max_mem: 2420M\n",
      "\u001b[32m[12/20 08:14:48 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 79  total_loss: 0.8695  loss_cls: 0.2034  loss_box_reg: 0.1466  loss_mask: 0.5477  loss_rpn_cls: 0.0009081  loss_rpn_loc: 0.004707    time: 0.3320  last_time: 0.2712  data_time: 0.0037  last_data_time: 0.0033   lr: 2.6407e-05  max_mem: 2420M\n",
      "\u001b[32m[12/20 08:14:54 d2.utils.events]: \u001b[0m eta: 0:01:03  iter: 99  total_loss: 0.7655  loss_cls: 0.1512  loss_box_reg: 0.1392  loss_mask: 0.4739  loss_rpn_cls: 0.0004072  loss_rpn_loc: 0.005455    time: 0.3280  last_time: 0.3164  data_time: 0.0035  last_data_time: 0.0034   lr: 3.3067e-05  max_mem: 2420M\n",
      "\u001b[32m[12/20 08:15:00 d2.utils.events]: \u001b[0m eta: 0:00:56  iter: 119  total_loss: 0.6829  loss_cls: 0.1177  loss_box_reg: 0.114  loss_mask: 0.4396  loss_rpn_cls: 0.0003652  loss_rpn_loc: 0.004942    time: 0.3258  last_time: 0.3154  data_time: 0.0034  last_data_time: 0.0038   lr: 3.9727e-05  max_mem: 2420M\n",
      "\u001b[32m[12/20 08:15:07 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 139  total_loss: 0.5795  loss_cls: 0.1059  loss_box_reg: 0.1283  loss_mask: 0.3368  loss_rpn_cls: 0.0004681  loss_rpn_loc: 0.004798    time: 0.3261  last_time: 0.3030  data_time: 0.0036  last_data_time: 0.0034   lr: 4.6387e-05  max_mem: 2420M\n",
      "\u001b[32m[12/20 08:15:13 d2.utils.events]: \u001b[0m eta: 0:00:44  iter: 159  total_loss: 0.5222  loss_cls: 0.097  loss_box_reg: 0.1332  loss_mask: 0.2901  loss_rpn_cls: 0.0001992  loss_rpn_loc: 0.004985    time: 0.3235  last_time: 0.2742  data_time: 0.0036  last_data_time: 0.0041   lr: 5.3047e-05  max_mem: 2420M\n",
      "\u001b[32m[12/20 08:15:19 d2.utils.events]: \u001b[0m eta: 0:00:38  iter: 179  total_loss: 0.4411  loss_cls: 0.08584  loss_box_reg: 0.1231  loss_mask: 0.215  loss_rpn_cls: 0.0004299  loss_rpn_loc: 0.003679    time: 0.3232  last_time: 0.3159  data_time: 0.0037  last_data_time: 0.0036   lr: 5.9707e-05  max_mem: 2420M\n",
      "\u001b[32m[12/20 08:15:26 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 199  total_loss: 0.4439  loss_cls: 0.09439  loss_box_reg: 0.144  loss_mask: 0.1857  loss_rpn_cls: 7.888e-05  loss_rpn_loc: 0.004076    time: 0.3219  last_time: 0.2808  data_time: 0.0036  last_data_time: 0.0037   lr: 6.6367e-05  max_mem: 2420M\n",
      "\u001b[32m[12/20 08:15:32 d2.utils.events]: \u001b[0m eta: 0:00:25  iter: 219  total_loss: 0.4144  loss_cls: 0.08238  loss_box_reg: 0.1336  loss_mask: 0.1799  loss_rpn_cls: 0.0001218  loss_rpn_loc: 0.003394    time: 0.3202  last_time: 0.2673  data_time: 0.0035  last_data_time: 0.0033   lr: 7.3027e-05  max_mem: 2420M\n",
      "\u001b[32m[12/20 08:15:38 d2.utils.events]: \u001b[0m eta: 0:00:18  iter: 239  total_loss: 0.3557  loss_cls: 0.07271  loss_box_reg: 0.1311  loss_mask: 0.1492  loss_rpn_cls: 0.0001184  loss_rpn_loc: 0.005013    time: 0.3198  last_time: 0.3449  data_time: 0.0035  last_data_time: 0.0035   lr: 7.9687e-05  max_mem: 2420M\n",
      "\u001b[32m[12/20 08:15:44 d2.utils.events]: \u001b[0m eta: 0:00:12  iter: 259  total_loss: 0.3851  loss_cls: 0.0715  loss_box_reg: 0.1429  loss_mask: 0.1545  loss_rpn_cls: 7.311e-05  loss_rpn_loc: 0.003991    time: 0.3196  last_time: 0.3132  data_time: 0.0036  last_data_time: 0.0036   lr: 8.6347e-05  max_mem: 2420M\n",
      "\u001b[32m[12/20 08:15:51 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 279  total_loss: 0.3868  loss_cls: 0.06931  loss_box_reg: 0.1446  loss_mask: 0.146  loss_rpn_cls: 8.379e-05  loss_rpn_loc: 0.004139    time: 0.3188  last_time: 0.2984  data_time: 0.0037  last_data_time: 0.0036   lr: 9.3007e-05  max_mem: 2420M\n",
      "\u001b[32m[12/20 08:15:58 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 299  total_loss: 0.3245  loss_cls: 0.05808  loss_box_reg: 0.1232  loss_mask: 0.127  loss_rpn_cls: 0.0001747  loss_rpn_loc: 0.005534    time: 0.3186  last_time: 0.3105  data_time: 0.0037  last_data_time: 0.0040   lr: 9.9667e-05  max_mem: 2420M\n",
      "\u001b[32m[12/20 08:15:58 d2.engine.hooks]: \u001b[0mOverall training speed: 298 iterations in 0:01:34 (0.3187 s / it)\n",
      "\u001b[32m[12/20 08:15:58 d2.engine.hooks]: \u001b[0mTotal training time: 0:01:41 (0:00:06 on hooks)\n",
      "\u001b[32m[12/20 08:16:20 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|    fish    | 1800         |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[12/20 08:16:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/20 08:16:20 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[12/20 08:16:20 d2.data.common]: \u001b[0mSerializing 1800 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/20 08:16:22 d2.data.common]: \u001b[0mSerialized dataset takes 1807.67 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/20 08:16:22 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa249353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output_detectron2'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "328ec9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/20 08:17:05 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from output_detectron2\\model_final.pth ...\n"
     ]
    }
   ],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.4\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "605ae94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = get_annotations(df_test_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6ed295db",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fish_metadata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m im \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_name\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      6\u001b[0m outputs \u001b[38;5;241m=\u001b[39m predictor(im)  \u001b[38;5;66;03m# format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\u001b[39;00m\n\u001b[0;32m      7\u001b[0m v \u001b[38;5;241m=\u001b[39m Visualizer(im[:, :, ::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m----> 8\u001b[0m                metadata\u001b[38;5;241m=\u001b[39m\u001b[43mfish_metadata\u001b[49m, \n\u001b[0;32m      9\u001b[0m                scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,\n\u001b[0;32m     10\u001b[0m                instance_mode\u001b[38;5;241m=\u001b[39mColorMode\u001b[38;5;241m.\u001b[39mIMAGE_BW   \u001b[38;5;66;03m# remove the colors of unsegmented pixels. This option is only available for segmentation models\u001b[39;00m\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     12\u001b[0m out \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39mdraw_instance_predictions(outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstances\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     13\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(out\u001b[38;5;241m.\u001b[39mget_image()[:, :, ::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fish_metadata' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x10000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "for d in random.sample(df_test, 3):\n",
    "    fig = plt.figure(figsize=(10, 100))\n",
    "    fig.add_subplot(15, 1, 1)\n",
    "    im = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=fish_metadata, \n",
    "                   scale=0.5,\n",
    "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
    "    )\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    plt.imshow(out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6706a5d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/20 08:17:39 d2.evaluation.coco_evaluation]: \u001b[0mTrying to convert 'fish_test' to COCO format ...\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/20 08:17:39 d2.data.datasets.coco]: \u001b[0mUsing previously cached COCO format annotations at 'output_detectron2\\fish_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.\n",
      "\u001b[32m[12/20 08:18:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/20 08:18:00 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[12/20 08:18:00 d2.data.common]: \u001b[0mSerializing 1800 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/20 08:18:01 d2.data.common]: \u001b[0mSerialized dataset takes 1807.64 MiB\n",
      "\u001b[32m[12/20 08:18:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 1800 batches\n",
      "\u001b[32m[12/20 08:18:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/1800. Dataloading: 0.0017 s/iter. Inference: 0.0734 s/iter. Eval: 0.0010 s/iter. Total: 0.0761 s/iter. ETA=0:02:16\n",
      "\u001b[32m[12/20 08:18:12 d2.evaluation.evaluator]: \u001b[0mInference done 78/1800. Dataloading: 0.0017 s/iter. Inference: 0.0727 s/iter. Eval: 0.0010 s/iter. Total: 0.0755 s/iter. ETA=0:02:10\n",
      "\u001b[32m[12/20 08:18:17 d2.evaluation.evaluator]: \u001b[0mInference done 145/1800. Dataloading: 0.0017 s/iter. Inference: 0.0726 s/iter. Eval: 0.0010 s/iter. Total: 0.0754 s/iter. ETA=0:02:04\n",
      "\u001b[32m[12/20 08:18:22 d2.evaluation.evaluator]: \u001b[0mInference done 212/1800. Dataloading: 0.0017 s/iter. Inference: 0.0724 s/iter. Eval: 0.0010 s/iter. Total: 0.0752 s/iter. ETA=0:01:59\n",
      "\u001b[32m[12/20 08:18:27 d2.evaluation.evaluator]: \u001b[0mInference done 279/1800. Dataloading: 0.0017 s/iter. Inference: 0.0723 s/iter. Eval: 0.0010 s/iter. Total: 0.0751 s/iter. ETA=0:01:54\n",
      "\u001b[32m[12/20 08:18:32 d2.evaluation.evaluator]: \u001b[0mInference done 346/1800. Dataloading: 0.0017 s/iter. Inference: 0.0723 s/iter. Eval: 0.0010 s/iter. Total: 0.0751 s/iter. ETA=0:01:49\n",
      "\u001b[32m[12/20 08:18:37 d2.evaluation.evaluator]: \u001b[0mInference done 413/1800. Dataloading: 0.0017 s/iter. Inference: 0.0723 s/iter. Eval: 0.0010 s/iter. Total: 0.0751 s/iter. ETA=0:01:44\n",
      "\u001b[32m[12/20 08:18:42 d2.evaluation.evaluator]: \u001b[0mInference done 480/1800. Dataloading: 0.0017 s/iter. Inference: 0.0723 s/iter. Eval: 0.0010 s/iter. Total: 0.0751 s/iter. ETA=0:01:39\n",
      "\u001b[32m[12/20 08:18:47 d2.evaluation.evaluator]: \u001b[0mInference done 547/1800. Dataloading: 0.0017 s/iter. Inference: 0.0723 s/iter. Eval: 0.0010 s/iter. Total: 0.0750 s/iter. ETA=0:01:34\n",
      "\u001b[32m[12/20 08:18:52 d2.evaluation.evaluator]: \u001b[0mInference done 614/1800. Dataloading: 0.0017 s/iter. Inference: 0.0722 s/iter. Eval: 0.0010 s/iter. Total: 0.0750 s/iter. ETA=0:01:28\n",
      "\u001b[32m[12/20 08:18:57 d2.evaluation.evaluator]: \u001b[0mInference done 681/1800. Dataloading: 0.0017 s/iter. Inference: 0.0722 s/iter. Eval: 0.0010 s/iter. Total: 0.0750 s/iter. ETA=0:01:23\n",
      "\u001b[32m[12/20 08:19:02 d2.evaluation.evaluator]: \u001b[0mInference done 748/1800. Dataloading: 0.0017 s/iter. Inference: 0.0722 s/iter. Eval: 0.0010 s/iter. Total: 0.0750 s/iter. ETA=0:01:18\n",
      "\u001b[32m[12/20 08:19:07 d2.evaluation.evaluator]: \u001b[0mInference done 815/1800. Dataloading: 0.0017 s/iter. Inference: 0.0722 s/iter. Eval: 0.0010 s/iter. Total: 0.0750 s/iter. ETA=0:01:13\n",
      "\u001b[32m[12/20 08:19:12 d2.evaluation.evaluator]: \u001b[0mInference done 882/1800. Dataloading: 0.0017 s/iter. Inference: 0.0722 s/iter. Eval: 0.0010 s/iter. Total: 0.0750 s/iter. ETA=0:01:08\n",
      "\u001b[32m[12/20 08:19:17 d2.evaluation.evaluator]: \u001b[0mInference done 949/1800. Dataloading: 0.0017 s/iter. Inference: 0.0722 s/iter. Eval: 0.0010 s/iter. Total: 0.0750 s/iter. ETA=0:01:03\n",
      "\u001b[32m[12/20 08:19:22 d2.evaluation.evaluator]: \u001b[0mInference done 1016/1800. Dataloading: 0.0017 s/iter. Inference: 0.0722 s/iter. Eval: 0.0010 s/iter. Total: 0.0750 s/iter. ETA=0:00:58\n",
      "\u001b[32m[12/20 08:19:27 d2.evaluation.evaluator]: \u001b[0mInference done 1083/1800. Dataloading: 0.0017 s/iter. Inference: 0.0722 s/iter. Eval: 0.0010 s/iter. Total: 0.0750 s/iter. ETA=0:00:53\n",
      "\u001b[32m[12/20 08:19:32 d2.evaluation.evaluator]: \u001b[0mInference done 1150/1800. Dataloading: 0.0017 s/iter. Inference: 0.0723 s/iter. Eval: 0.0010 s/iter. Total: 0.0751 s/iter. ETA=0:00:48\n",
      "\u001b[32m[12/20 08:19:37 d2.evaluation.evaluator]: \u001b[0mInference done 1217/1800. Dataloading: 0.0017 s/iter. Inference: 0.0723 s/iter. Eval: 0.0010 s/iter. Total: 0.0751 s/iter. ETA=0:00:43\n",
      "\u001b[32m[12/20 08:19:42 d2.evaluation.evaluator]: \u001b[0mInference done 1284/1800. Dataloading: 0.0017 s/iter. Inference: 0.0723 s/iter. Eval: 0.0010 s/iter. Total: 0.0751 s/iter. ETA=0:00:38\n",
      "\u001b[32m[12/20 08:19:47 d2.evaluation.evaluator]: \u001b[0mInference done 1351/1800. Dataloading: 0.0017 s/iter. Inference: 0.0723 s/iter. Eval: 0.0010 s/iter. Total: 0.0751 s/iter. ETA=0:00:33\n",
      "\u001b[32m[12/20 08:19:52 d2.evaluation.evaluator]: \u001b[0mInference done 1418/1800. Dataloading: 0.0017 s/iter. Inference: 0.0723 s/iter. Eval: 0.0010 s/iter. Total: 0.0751 s/iter. ETA=0:00:28\n",
      "\u001b[32m[12/20 08:19:57 d2.evaluation.evaluator]: \u001b[0mInference done 1485/1800. Dataloading: 0.0017 s/iter. Inference: 0.0723 s/iter. Eval: 0.0010 s/iter. Total: 0.0751 s/iter. ETA=0:00:23\n",
      "\u001b[32m[12/20 08:20:02 d2.evaluation.evaluator]: \u001b[0mInference done 1552/1800. Dataloading: 0.0017 s/iter. Inference: 0.0723 s/iter. Eval: 0.0010 s/iter. Total: 0.0751 s/iter. ETA=0:00:18\n",
      "\u001b[32m[12/20 08:20:07 d2.evaluation.evaluator]: \u001b[0mInference done 1619/1800. Dataloading: 0.0017 s/iter. Inference: 0.0723 s/iter. Eval: 0.0010 s/iter. Total: 0.0751 s/iter. ETA=0:00:13\n",
      "\u001b[32m[12/20 08:20:12 d2.evaluation.evaluator]: \u001b[0mInference done 1686/1800. Dataloading: 0.0017 s/iter. Inference: 0.0723 s/iter. Eval: 0.0010 s/iter. Total: 0.0751 s/iter. ETA=0:00:08\n",
      "\u001b[32m[12/20 08:20:17 d2.evaluation.evaluator]: \u001b[0mInference done 1755/1800. Dataloading: 0.0017 s/iter. Inference: 0.0722 s/iter. Eval: 0.0010 s/iter. Total: 0.0750 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/20 08:20:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:15.089539 (0.075259 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/20 08:20:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:02:09 (0.072211 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/20 08:20:21 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[12/20 08:20:21 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_detectron2\\coco_instances_results.json\n",
      "\u001b[32m[12/20 08:20:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[12/20 08:20:21 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[12/20 08:20:21 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.08 seconds.\n",
      "\u001b[32m[12/20 08:20:21 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[12/20 08:20:21 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.549\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.939\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.568\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.535\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.549\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.631\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.634\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.634\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.536\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.634\n",
      "\u001b[32m[12/20 08:20:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 54.862 | 93.854 | 56.799 |  nan  | 53.465 | 54.877 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/20 08:20:21 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[12/20 08:20:21 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[12/20 08:20:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.27 seconds.\n",
      "\u001b[32m[12/20 08:20:22 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[12/20 08:20:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.569\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.811\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.696\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.573\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.647\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.650\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.650\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.654\n",
      "\u001b[32m[12/20 08:20:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 56.887 | 81.075 | 69.550 |  nan  | 0.000 | 57.278 |\n",
      "\u001b[32m[12/20 08:20:22 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "OrderedDict([('bbox', {'AP': 54.861849733805236, 'AP50': 93.85364068576723, 'AP75': 56.79889989834336, 'APs': nan, 'APm': 53.46534653465347, 'APl': 54.877468964550836}), ('segm', {'AP': 56.88741603667157, 'AP50': 81.07501136195368, 'AP75': 69.55045020112168, 'APs': nan, 'APm': 0.0, 'APl': 57.27823998230189})])\n"
     ]
    }
   ],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "evaluator = COCOEvaluator(\"fish_test\", output_dir=\"output_detectron2\")\n",
    "val_loader = build_detection_test_loader(cfg, \"fish_test\")\n",
    "print(inference_on_dataset(predictor.model, val_loader, evaluator))\n",
    "# another equivalent way to evaluate the model is to use `trainer.test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b78e28c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IoU: 82.5\n"
     ]
    }
   ],
   "source": [
    "iou_sum = 0\n",
    "iou_list = []\n",
    "for annon in df_test:\n",
    "    im = cv2.imread(annon['file_name'])\n",
    "    outputs = predictor(im)\n",
    "    try:\n",
    "        pred = outputs['instances'].pred_masks[0]\n",
    "        pred = pred.to('cpu')\n",
    "        pred_int = pred.long()\n",
    "        pred_np = pred_int.numpy()\n",
    "        iou_pred = iou_np(annon['mask'], pred_np)\n",
    "    except:\n",
    "        iou_pred = 0\n",
    "    iou_sum += iou_pred\n",
    "    iou_list.append(iou_pred)\n",
    "\n",
    "iou = (iou_sum / len(df_test)) * 100\n",
    "print(f'IoU: {iou:.1f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
