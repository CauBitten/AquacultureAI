{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81373f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from Utils.build_dataset import paths_dataset\n",
    "from torchvision import transforms\n",
    "from Models.FCN import FCN\n",
    "from Utils.FishDataset import FishDataset\n",
    "from Utils.training import training_loop, predict, iou_np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4e0492",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float32\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5949db",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {0 : \"Black Sea Sprat\", 1 : \"Sea Bass\", 2 : \"Red Mullet\", 3 : \"Trout\", 4 : \"Striped Red Mullet\", \n",
    "              5 : \"Shrimp\", 6 : \"Red Sea Bream\", 7 : \"Hourse Mackerel\", 8 : \"Gilt-Head Bream\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1dfc55",
   "metadata": {},
   "source": [
    "## Carregando as Imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2336bade",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Dataset/Fish_Dataset/Fish_Dataset/'\n",
    "df_train_pd, df_valid_pd, df_test_pd = paths_dataset(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391a8cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 256\n",
    "threshold = 0.5\n",
    "transform = transforms.Compose([transforms.ToPILImage(), transforms.Resize((img_size, img_size)), transforms.ToTensor(), \n",
    "                               transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "transform_mask = transforms.Compose([transforms.ToPILImage(), transforms.Resize((img_size, img_size)), transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9d95f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = FishDataset(df_train_pd, transform, transform_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45be0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = FishDataset(df_valid_pd, transform, transform_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e119aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = FishDataset(df_test_pd, transform, transform_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa849a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6042f834",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    n = random.randint(0, (len(df_train)))\n",
    "    fig = plt.figure(figsize=(10, 100))\n",
    "    \n",
    "    fig.add_subplot(15, 2, 1)\n",
    "    #plt.title(label_dict[df_train[n][2]])\n",
    "    plt.imshow(df_train[n][0].permute(1, 2, 0))\n",
    "    \n",
    "    fig.add_subplot(15, 2, 2)\n",
    "    #plt.title(label_dict[df_train[n][2]])\n",
    "    plt.imshow(df_train[n][1].permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3eb3258",
   "metadata": {},
   "source": [
    "## Construindo o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3987c3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 32\n",
    "lr = 1e-3\n",
    "train_loader = DataLoader(df_train, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "valid_loader = DataLoader(df_valid, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(df_test, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "sigmoid = torch.nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170bf582",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf566b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses_list = []\n",
    "train_loss_final = []\n",
    "train_iou_list = []\n",
    "train_iou_final = []\n",
    "valid_losses_list = []\n",
    "valid_loss_final = []\n",
    "valid_iou_list = []\n",
    "valid_iou_final = []\n",
    "test_iou_list = []\n",
    "test_acc_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b1d75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list_test = list(df_test_pd['image'])\n",
    "mask_list_test = list(df_test_pd['mask'])\n",
    "label_list_test = list(df_test_pd['label'])\n",
    "label_id_list_test = list(df_test_pd['label_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f73098",
   "metadata": {},
   "source": [
    "### Configuração dos Experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58e7a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_number = 1 #id do experimento, será usado para salvar o modelo com nome único\n",
    "n_exps = 30 #Quantidade de experimentos que serão executados\n",
    "path_pkl = 'Saved Models/FCN Segmentation' #Path da pasta onde serão salvos os arquivos pkl\n",
    "path_metrics = 'Metrics' #Path da pasta onde será salvo o arquivo csv com as métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501be3fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for n in range(exp_number, (n_exps)):\n",
    "    print(\"Run {0} out of {1}\".format(n, n_exps))\n",
    "    model = FCN()\n",
    "    model.to(device, dtype=dtype)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "    model, optimizer, train_losses, valid_losses, train_iou, valid_iou = training_loop(epochs, model, train_loader, \n",
    "                                                                                       valid_loader, criterion, optimizer, \n",
    "                                                                                       device, dtype)\n",
    "    train_losses_list.append(train_losses)\n",
    "    train_iou_list.append(train_iou)\n",
    "    valid_losses_list.append(valid_losses)\n",
    "    valid_iou_list.append(valid_iou)\n",
    "    train_loss_final.append(train_losses[-1])\n",
    "    train_iou_final.append(train_iou[-1])\n",
    "    valid_loss_final.append(valid_losses[-1])\n",
    "    valid_iou_final.append(valid_iou[-1])\n",
    "    \n",
    "    save_name = f'{path_pkl}/fcn_segmentation_run_{n}.pkl'\n",
    "    torch.save(model.state_dict(), save_name)\n",
    "    print(f'Model saved in {save_name}')\n",
    "    \n",
    "    running_iou = 0\n",
    "    for i in range(len(img_list_test)):\n",
    "        label_id = label_id_list_test[i]\n",
    "        image = cv2.imread(img_list_test[i])\n",
    "        image = cv2.resize(image, (img_size, img_size))\n",
    "        mask = cv2.imread(mask_list_test[i])\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "        mask = cv2.resize(mask, (img_size, img_size))\n",
    "        pred = predict(model, image, img_size, threshold, device)\n",
    "        iou_pred = iou_np(mask, pred)\n",
    "        running_iou += iou_pred\n",
    "        \n",
    "\n",
    "    iou_test = (running_iou / len(img_list_test)) * 100\n",
    "    test_iou_list.append(iou_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95affb0c",
   "metadata": {},
   "source": [
    "## Salvando as Métricas dos experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e9899d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {'train_loss_list': train_losses_list,\n",
    "          'train_loss': train_loss_final,\n",
    "          'train_iou_list' : train_iou_list,\n",
    "          'train_iou': train_iou_final,\n",
    "          'valid_losses_list': valid_losses_list,\n",
    "          'valid_loss': valid_loss_final,\n",
    "          'valid_iou_list': valid_iou_list,\n",
    "          'valid_iou': valid_iou_final,\n",
    "          'test_iou': test_iou_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f69ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = pd.DataFrame(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd73f8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d472d8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_csv = f'{path_metrics}/metrics_fcn_segmentation.csv'\n",
    "df_metrics.to_csv(path_csv, sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
